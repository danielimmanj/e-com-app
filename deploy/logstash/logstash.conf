input {
  file {
    # Specify the path where your application logs are stored
    path => "/home/daniel/Documents/logs/eCommerce/*.log"
    type => "eCommerce-logs"

    # Read new log entries from the end of the file
    start_position => "beginning"

    # Handle file rotation
    sincedb_path => "/dev/null"
  }
}

filter {
  # Extract the microservice name from the file path (assuming file names like user-service.log)
  grok {
    match => { "path" => "/home/daniel/Documents/logs/eCommerce/%{GREEDYDATA:service_name}.log" }
  }

  # Detailed Grok pattern to parse log messages
  grok {
    match => { 
      "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{DATA:thread}\] %{LOGLEVEL:loglevel} %{JAVACLASS:class} - %{GREEDYDATA:logmessage}" 
    }
  }

  # Optionally add metadata to logs, like application or environment
  mutate {
    add_field => { "app_name" => "eCommerce" }
    add_field => { "environment" => "production" }
  }

  # Convert timestamp to proper format
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
  }
}

output {
  # Output to Elasticsearch (change this to your Elasticsearch host)
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "ecommerce-logs-%{+YYYY.MM.dd}" # Daily index format
  }

  # Optional: Output to stdout for debugging
  stdout { codec => rubydebug }
}
